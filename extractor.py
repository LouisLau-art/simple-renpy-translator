#!/usr/bin/env python3
"""
RenPy æ–‡æœ¬æå–å™¨ (Extractor)
é€’å½’æ‰«æ game/ ç›®å½•ä¸‹çš„ .rpy æ–‡ä»¶ï¼Œæå–å¯ç¿»è¯‘çš„æ–‡æœ¬
"""

import hashlib
import json
import re
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
import sys


class RenPyExtractor:
    """RenPy æ–‡ä»¶æ–‡æœ¬æå–å™¨"""
    
    # å…³é”®å­—æ¨¡å¼ï¼Œéœ€è¦æ’é™¤çš„è¡Œ
    IGNORE_PATTERNS = [
        re.compile(r'^\s*label\s+', re.MULTILINE),          # æ ‡ç­¾å®šä¹‰
        re.compile(r'^\s*jump\s+', re.MULTILINE),          # è·³è½¬è¯­å¥
        re.compile(r'^\s*call\s+', re.MULTILINE),          # è°ƒç”¨è¯­å¥
        re.compile(r'^\s*scene\s+', re.MULTILINE),         # åœºæ™¯åˆ‡æ¢
        re.compile(r'^\s*show\s+', re.MULTILINE),          # æ˜¾ç¤ºå›¾åƒ
        re.compile(r'^\s*hide\s+', re.MULTILINE),          # éšè—å›¾åƒ
        re.compile(r'^\s*play\s+', re.MULTILINE),          # æ’­æ”¾éŸ³é¢‘
        re.compile(r'^\s*stop\s+', re.MULTILINE),          # åœæ­¢éŸ³é¢‘
        re.compile(r'^\s*with\s+', re.MULTILINE),          # è½¬æ¢æ•ˆæœ
        re.compile(r'^\s*init\s*:', re.MULTILINE),         # åˆå§‹åŒ–å—
        re.compile(r'^\s*python\s*:', re.MULTILINE),       # Python å—
        re.compile(r'^\s*#.*$', re.MULTILINE),             # æ³¨é‡Šè¡Œ
        re.compile(r'^\s*$', re.MULTILINE),                # ç©ºè¡Œ
    ]
    
    # æ–‡ä»¶æ‰©å±•åæ¨¡å¼ï¼Œç”¨äºæ’é™¤æ–‡ä»¶è·¯å¾„
    FILE_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.gif', '.ogg', '.mp3', '.wav', '.mp4', '.webm', '.ttf', '.otf', '.pyc'}
    
    # ç›®å½•é»‘åå•ï¼šè¿™äº›ç›®å½•ä¸åº”è¯¥è¢«æ‰«æ
    DIRECTORY_BLACKLIST = ['tl', 'renpy', 'cache', 'saved']
    
    # æ–‡ä»¶åé»‘åå•ï¼šè¿™äº›æ–‡ä»¶ä¸åº”è¯¥è¢«æ‰«æ
    FILE_PREFIX_BLACKLIST = ['00', 'gui.', 'gui_']
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        self.extracted_texts: List[Dict[str, Any]] = []
        self.skipped_files = []
        self.total_files = 0
    
    def should_skip_file(self, file_path: Path, game_dir: Path) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¯¥æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            game_dir: æ¸¸æˆæ ¹ç›®å½•
            
        Returns:
            True è¡¨ç¤ºåº”è¯¥è·³è¿‡
        """
        # æ£€æŸ¥æ–‡ä»¶åå‰ç¼€é»‘åå•
        for prefix in self.FILE_PREFIX_BLACKLIST:
            if file_path.name.startswith(prefix):
                return True
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨é»‘åå•ç›®å½•ä¸­
        relative_path = file_path.relative_to(game_dir)
        
        # æ£€æŸ¥è·¯å¾„ä¸­çš„æ¯ä¸ªéƒ¨åˆ†æ˜¯å¦åœ¨é»‘åå•ä¸­
        for part in relative_path.parts:
            if part in self.DIRECTORY_BLACKLIST:
                return True
        
        return False
    
    def extract_from_game_directory(self, game_dir: Path = Path("game")) -> List[Dict[str, Any]]:
        """
        ä» game ç›®å½•æå–æ‰€æœ‰å¯ç¿»è¯‘æ–‡æœ¬
        
        Args:
            game_dir: game ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„ game
            
        Returns:
            æå–çš„æ–‡æœ¬åˆ—è¡¨
        """
        print(f"ğŸ” å¼€å§‹æ‰«æ game ç›®å½•: {game_dir.absolute()}")
        
        if not game_dir.exists():
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° game ç›®å½•: {game_dir}")
            return []
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .rpy æ–‡ä»¶
        all_rpy_files = list(game_dir.rglob("*.rpy"))
        
        # è¿‡æ»¤æ‰ä¸éœ€è¦çš„æ–‡ä»¶
        rpy_files = []
        for rpy_file in all_rpy_files:
            if self.should_skip_file(rpy_file, game_dir):
                continue
            rpy_files.append(rpy_file)
        
        print(f"ğŸ“ æ€»å…±æ‰¾åˆ° {len(all_rpy_files)} ä¸ª .rpy æ–‡ä»¶ï¼Œè¿‡æ»¤åå‰©ä¸‹ {len(rpy_files)} ä¸ªæ–‡ä»¶")
        
        # ç»Ÿè®¡è·³è¿‡çš„æ–‡ä»¶
        skipped_count = len(all_rpy_files) - len(rpy_files)
        if skipped_count > 0:
            print(f"âš ï¸ è·³è¿‡äº† {skipped_count} ä¸ªæ–‡ä»¶ (åŒ…æ‹¬ç¿»è¯‘æ–‡ä»¶ã€å¼•æ“æ–‡ä»¶ç­‰)")
        
        # æå–æ¯ä¸ªæ–‡ä»¶ä¸­çš„æ–‡æœ¬
        for rpy_file in rpy_files:
            self._extract_from_file(rpy_file)
        
        print(f"âœ… æå–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(self.extracted_texts)} ä¸ªå¯ç¿»è¯‘æ–‡æœ¬")
        return self.extracted_texts
    
    def _extract_from_file(self, file_path: Path) -> None:
        """
        ä»å•ä¸ª .rpy æ–‡ä»¶ä¸­æå–æ–‡æœ¬
        
        Args:
            file_path: .rpy æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return
        
        for line_num, line in enumerate(lines, 1):
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è¿™ä¸€è¡Œ
            if self._should_ignore_line(line):
                continue
            
            # æå–åŒå¼•å·å†…çš„æ–‡æœ¬
            self._extract_quoted_texts(line, file_path, line_num)
    
    def _should_ignore_line(self, line: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¿™ä¸€è¡Œ
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            True è¡¨ç¤ºåº”è¯¥å¿½ç•¥ï¼ŒFalse è¡¨ç¤ºéœ€è¦å¤„ç†
        """
        stripped_line = line.strip()
        
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå¿½ç•¥æ¨¡å¼
        for pattern in self.IGNORE_PATTERNS:
            if pattern.match(line):
                return True
        
        return False
    
    def _extract_quoted_texts(self, line: str, file_path: Path, line_num: int) -> None:
        """
        æå–ä¸€è¡Œä¸­çš„æ‰€æœ‰å¼•å·æ–‡æœ¬
        
        Args:
            line: æ–‡æœ¬è¡Œ
            file_path: æ–‡ä»¶è·¯å¾„
            line_num: è¡Œå·
        """
        # åŒ¹é…åŒå¼•å·å†…çš„å†…å®¹
        pattern = r'"([^"]*)"'
        matches = re.finditer(pattern, line)
        
        for match in matches:
            text = match.group(1).strip()
            
            # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦éœ€è¦ç¿»è¯‘
            if self._is_translatable_text(text):
                # ç”Ÿæˆå”¯ä¸€ ID
                text_id = self._generate_id(file_path, line_num, text)
                
                # åˆ¤æ–­æ–‡æœ¬ç±»å‹
                text_type = self._classify_text_type(line, text)
                
                # åˆ›å»ºæ–‡æœ¬æ¡ç›®
                text_entry = {
                    "id": text_id,
                    "file": str(file_path.relative_to(file_path.parent.parent)),  # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                    "line": line_num,
                    "type": text_type,
                    "original": text,
                    "translated": None,  # åˆå§‹ä¸º nullï¼Œç­‰å¾…ç¿»è¯‘å™¨å¡«å……
                    "context": self._extract_context(line, text)
                }
                
                self.extracted_texts.append(text_entry)
    
    def _is_translatable_text(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦éœ€è¦ç¿»è¯‘
        
        Args:
            text: è¦æ£€æŸ¥çš„æ–‡æœ¬
            
        Returns:
            True è¡¨ç¤ºéœ€è¦ç¿»è¯‘ï¼ŒFalse è¡¨ç¤ºä¸éœ€è¦
        """
        # æ¸…ç†æ–‡æœ¬
        cleaned_text = text.strip().strip('"\'')
        
        # è·³è¿‡å¾ˆçŸ­çš„æ–‡æœ¬
        if len(cleaned_text) < 2:
            return False
        
        # 1. è¿‡æ»¤é¢œè‰²ä»£ç  (åå…­è¿›åˆ¶æ ¼å¼)
        if self._is_color_code(cleaned_text):
            return False
        
        # 2. è¿‡æ»¤ç³»ç»ŸæŒ‡ä»¤
        if self._is_system_instruction(cleaned_text):
            return False
        
        # 3. è¿‡æ»¤çº¯ä»£ç /æ ‡è¯†ç¬¦
        if self._is_code_identifier(cleaned_text):
            return False
        
        # 4. è·³è¿‡çœ‹èµ·æ¥åƒä»£ç æˆ–å˜é‡çš„æ–‡æœ¬
        if cleaned_text.startswith(('$', '{', '[')) or '{' in cleaned_text:
            return False
        
        # 5. è·³è¿‡æ–‡ä»¶è·¯å¾„
        if self._is_file_path(cleaned_text):
            return False
        
        # 6. è·³è¿‡çœ‹èµ·æ¥åƒæ ‡è¯†ç¬¦çš„å•è¯
        if len(cleaned_text.split()) == 1 and re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', cleaned_text):
            return False
        
        # 7. è·³è¿‡å…¨æ•°å­—æˆ–å…¨ç‰¹æ®Šå­—ç¬¦
        letters = sum(1 for c in cleaned_text if c.isalpha())
        if letters == 0:
            return False
        
        return True
    
    def _is_color_code(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯é¢œè‰²ä»£ç """
        # åå…­è¿›åˆ¶é¢œè‰²æ ¼å¼ (#fff, #ffffff, #123456)
        hex_pattern = re.compile(r'^#[0-9a-fA-F]{3,6}$')
        if hex_pattern.match(text):
            return True
        
        # å¸¸è§çš„é¢œè‰²å€¼æ¨¡å¼
        color_patterns = [
            r'rgb\(\s*\d+\s*,\s*\d+\s*,\s*\d+\s*\)',  # rgb(255, 0, 0)
            r'rgba\(\s*\d+\s*,\s*\d+\s*,\s*\d+\s*,\s*[\d.]+\s*\)',  # rgba(255, 0, 0, 0.5)
        ]
        
        for pattern in color_patterns:
            if re.match(pattern, text):
                return True
        
        return False
    
    def _is_system_instruction(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»ŸæŒ‡ä»¤"""
        # æ£€æŸ¥æ˜¯å¦ä»¥å¸¸è§ç³»ç»ŸæŒ‡ä»¤å¼€å¤´
        system_patterns = [
            r'^auto\s+voice:',           # auto voice: [_voice.auto_file!sq]
            r'^auto:',                   # auto: text
            r'^\{[^}]*\}[^}]*\{[^}]*\}', # å¤æ‚æ ¼å¼æ–‡æœ¬ {color=#fff}text{/color}
        ]
        
        for pattern in system_patterns:
            if re.search(pattern, text):
                return True
        
        return False
    
    def _is_code_identifier(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯çº¯ä»£ç /æ ‡è¯†ç¬¦"""
        # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯å¤§å†™å­—æ¯å’Œæ•°å­—ï¼ˆé€šå¸¸æ˜¯å°å·¥å…·æˆ–æ ‡è¯†ç¬¦ï¼‰
        if text.isupper() and any(c.isalpha() for c in text) and any(c.isdigit() for c in text):
            # å¦‚æœåŒ…å«å­—æ¯ä¸”æ²¡æœ‰ç©ºæ ¼ï¼Œå¯èƒ½æ˜¯æ ‡è¯†ç¬¦
            if ' ' not in text and len(text) <= 20:
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„ä»£ç æ¨¡å¼
        code_patterns = [
            r'^[a-zA-Z_][a-zA-Z0-9_]*[-_][a-zA-Z0-9_]*$',  # identifier_like_this
            r'^[A-Z]{2,}[0-9]+$',                           # CONSTANTS123
            r'^[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+$',           # class.method
        ]
        
        for pattern in code_patterns:
            if re.match(pattern, text):
                return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„åç¼€ï¼ˆé€šå¸¸è¡¨ç¤ºéè‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼‰
        code_suffixes = ['.py', '.rpy', '.txt', '.json', '.xml']
        for suffix in code_suffixes:
            if text.endswith(suffix):
                return True
        
        return False
    
    def _is_file_path(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åƒæ–‡ä»¶è·¯å¾„
        
        Args:
            text: è¦æ£€æŸ¥çš„æ–‡æœ¬
            
        Returns:
            True è¡¨ç¤ºåƒæ–‡ä»¶è·¯å¾„
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶æ‰©å±•å
        for ext in self.FILE_EXTENSIONS:
            if ext in text.lower():
                return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è·¯å¾„åˆ†éš”ç¬¦
        if '/' in text or '\\' in text:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åƒ RenPy èµ„æºè·¯å¾„
        if text.startswith(('images/', 'audio/', 'game/', 'gui/')):
            return True
        
        return False
    
    def _generate_id(self, file_path: Path, line_num: int, text: str) -> str:
        """
        ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            line_num: è¡Œå·
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            8ä½å“ˆå¸Œ ID
        """
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„ã€è¡Œå·å’Œæ–‡æœ¬å†…å®¹ç”Ÿæˆ MD5 å“ˆå¸Œ
        content = f"{file_path.name}_{line_num}_{text[:20]}"
        hash_obj = hashlib.md5(content.encode('utf-8'))
        return f"{file_path.stem}_{line_num}_{hash_obj.hexdigest()[:8]}"
    
    def _classify_text_type(self, line: str, text: str) -> str:
        """
        åˆ†ç±»æ–‡æœ¬ç±»å‹
        
        Args:
            line: åŸå§‹è¡Œ
            text: æå–çš„æ–‡æœ¬
            
        Returns:
            'dialogue' æˆ– 'string'
        """
        stripped_line = line.strip()
        
        # æ£€æŸ¥æ˜¯å¦åƒå¯¹è¯ï¼ˆè§’è‰²å + æ–‡æœ¬ï¼‰
        dialogue_patterns = [
            r'^[a-zA-Z_][a-zA-Z0-9_]*\s+"',  # character_name "text"
            r'^[a-zA-Z_][a-zA-Z0-9_]*\s+"{',  # character_name "{text"
        ]
        
        for pattern in dialogue_patterns:
            if re.match(pattern, stripped_line):
                return 'dialogue'
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥å¯¹è¯ï¼ˆåªæœ‰å¼•å·ï¼‰
        if stripped_line.startswith('"') or stripped_line.endswith('"'):
            return 'dialogue'
        
        # å…¶ä»–æƒ…å†µé»˜è®¤ä¸ºå­—ç¬¦ä¸²
        return 'string'
    
    def _extract_context(self, line: str, text: str) -> Optional[str]:
        """
        æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            line: åŸå§‹è¡Œ
            text: æå–çš„æ–‡æœ¬
            
        Returns:
            ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²æˆ– None
        """
        context_parts = []
        
        # æå–è§’è‰²å
        character_match = re.match(r'^\s*([a-zA-Z_][a-zA-Z0-9_]*)', line)
        if character_match:
            character = character_match.group(1)
            if not character.lower() in ['if', 'else', 'while', 'for', 'with', 'scene', 'show', 'hide']:
                context_parts.append(character)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²å˜é‡ï¼Œå¯èƒ½æœ‰æ›´å¤šä¿¡æ¯
        if '=' in line and '"' in line:
            var_match = re.match(r'^\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*=', line)
            if var_match:
                var_name = var_match.group(1)
                if not var_name.lower() in ['version', 'save_name', 'config', 'gui']:
                    context_parts.append(f"var:{var_name}")
        
        return ' '.join(context_parts) if context_parts else None
    
    def save_to_json(self, output_file: Path = Path("translation_work.json")) -> bool:
        """
        ä¿å­˜æå–çš„æ–‡æœ¬åˆ° JSON æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.extracted_texts, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ æå–ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="RenPy æ–‡æœ¬æå–å™¨ - æå– RenPy æ¸¸æˆä¸­çš„å¯ç¿»è¯‘æ–‡æœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python extractor.py                                    # æå–å½“å‰ç›®å½•ä¸‹çš„ game/
  python extractor.py -g /path/to/game/dir              # æŒ‡å®šæ¸¸æˆç›®å½•
  python extractor.py -o output.json                    # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python extractor.py --game-dir /path --output result.json  # æŒ‡å®šç›®å½•å’Œè¾“å‡ºæ–‡ä»¶
        """
    )
    
    parser.add_argument(
        '-g', '--game-dir',
        type=str,
        help='æ¸¸æˆç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•ä¸‹çš„ game/)',
        default=None
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        help='è¾“å‡º JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: translation_work.json)',
        default='translation_work.json'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version='%(prog)s 1.0.0'
    )
    
    args = parser.parse_args()
    
    print("ğŸ® RenPy æ–‡æœ¬æå–å™¨ (Extractor)")
    print("=" * 50)
    
    # è§£ææ¸¸æˆç›®å½•è·¯å¾„
    if args.game_dir:
        game_dir = Path(args.game_dir)
        print(f"ğŸ¯ æŒ‡å®šæ¸¸æˆç›®å½•: {game_dir.absolute()}")
    else:
        game_dir = Path("game")
        print(f"ğŸ¯ ä½¿ç”¨é»˜è®¤ç›®å½•: {game_dir.absolute()}")
    
    # è§£æè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = Path(args.output)
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_file.absolute()}")
    print()
    
    # åˆ›å»ºæå–å™¨å®ä¾‹
    extractor = RenPyExtractor()
    
    # æå–æ–‡æœ¬
    extracted_texts = extractor.extract_from_game_directory(game_dir)
    
    if not extracted_texts:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç¿»è¯‘çš„æ–‡æœ¬")
        return
    
    # ä¿å­˜åˆ° JSON æ–‡ä»¶
    if extractor.save_to_json(output_file):
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æå–ç»Ÿè®¡:")
        dialogue_count = sum(1 for item in extracted_texts if item['type'] == 'dialogue')
        string_count = sum(1 for item in extracted_texts if item['type'] == 'string')
        
        print(f"   å¯¹è¯æ–‡æœ¬: {dialogue_count}")
        print(f"   å­—ç¬¦ä¸²: {string_count}")
        print(f"   æ€»è®¡: {len(extracted_texts)}")
        
        print(f"\nğŸ¯ æå–å®Œæˆï¼ç°åœ¨å¯ä»¥å°† {output_file} æäº¤ç»™ç¿»è¯‘å™¨ã€‚")
    else:
        print("âŒ æå–å¤±è´¥")


if __name__ == "__main__":
    main()